{"basics":{"name":"Shubham Nagar","label":"Data Architect & Analyst","image":"","email":"mail.shubhamnagar@gmail.com","phone":"(32) 468035870","url":"https://shubham184.github.io","summary":"I am an innovative Data Architect & Analyst with over 11 years of experience in designing and implementing scalable data architectures for operational landscapes. My expertise lies in guiding software teams to create efficient data integration strategies that align with business vision and drive digital transformation. I excel at developing sustainable data solutions that empower autonomous teams, facilitate cross-functional collaboration, and support the evolution towards modern software practices. With a strong background in data governance and cloud technologies, I ensure robust, compliant, and future-proof data ecosystems that enable organizations to leverage their data assets effectively.","location":{"address":"","postalCode":"","city":"","countryCode":"","region":""},"profiles":[]},"work":[{"name":"Fujitsu","position":"BI & Data Architect | Data Analyst","startDate":"2019-01-01","endDate":"","summary":"Leading data architecture strategies and implementations for global clients, improving data accessibility and analytics capabilities.","highlights":["Designed and implemented a comprehensive data architecture strategy for a global supply chain and logistics customer, improving data accessibility by 35% and streamlining reporting processes across their international operations.","Led the integration of ESG reporting standards (EFRAG guidelines, XBRL frameworks) into a unified data system, utilizing Python, SQL, SSIS, and Apache Airflow for ETL processes, resulting in simplified complex reporting.","Developed high-impact dashboards and advanced data visualizations using Power BI, Tableau, and Qlik Sense, enhancing decision-making processes for key stakeholders.","Architected and implemented scalable data warehousing solutions using Snowflake and Azure Synapse Analytics for different enterprise clients. The solutions significantly boosted decision-making processes across various business domains.","Designed and managed data pipelines for validation, transformation, and cleaning using Spark and Python scripts, improving data quality and reliability while reducing processing time by 25%.","Optimized data retrieval and reporting processes using SQL, SSRS, and SSIS, resulting in a 30% improvement in query performance and streamlined data integration workflows.","Led the development of a data-driven AI platform integrating Python, FastAPI, and Next.js, enabling efficient management of AI-powered analytics tools and improving decision making.","Provided guidance on data modeling and integration strategies for multiple projects, ensuring consistency and adherence to best practices in data architecture, which led to a 30% reduction in data redundancy and improved overall data integrity.","Participated regularly in data governance committees, contributing insights on data quality, metadata management, and data lineage, which helped shape company-wide data policies and standards."]},{"name":"Cognizant","position":"Data Analyst | Automation","startDate":"2013-01-01","endDate":"2018-12-31","summary":"Developed and optimized ETL processes, implemented data quality checks, and created complex SQL queries for multiple client projects.","highlights":["Led the integration of RPA and AI tools to automate customer segmentation and market basket analysis for a supermarket chain, increasing customer retention rate by 30% through improved loyalty programs and promotional strategies.","Developed and optimized ETL processes using SQL Server Integration Services (SSIS) and Python, enhancing the efficiency and reliability of data pipelines for multiple client projects.","Created and maintained complex SQL queries and stored procedures to support data analysis and reporting needs, improving query performance by an average of 25%.","Collaborated with cross-functional teams to identify data requirements and translate them into technical specifications for ETL processes and data warehouse design.","Implemented data quality checks and validation rules within ETL processes, reducing data errors by 20% and improving overall data reliability."]}],"education":[{"institution":"West Bengal University","location":"India","area":"Technology","studyType":"Bachelor's","startDate":"2009-01-01","endDate":"2013-01-01"}],"certificates":[{"name":"Google Advanced Data Analytics Certification","issuer":"Google"},{"name":"Google Business Intelligence Professional Certification","issuer":"Google"},{"name":"Neo4j Graph Database","issuer":"Neo4j"},{"name":"Azure Solution Architect / Data Engineering / AI","issuer":"Microsoft"},{"name":"Azure and AWS Databricks Solution Architect","issuer":"Databricks"}],"skills":[{"name":"Data Architecture","keywords":["Data Integration Strategies","Operational Data Modeling","Data Governance Frameworks"]},{"name":"Modern Software Architectures","keywords":["Microservices","Event-Driven Architecture","API-First Design"]},{"name":"Data Integration & ETL","keywords":["Apache Kafka","Databricks","Talend","Apache Airflow","SQL Server Integration Services (SSIS)"]},{"name":"Cloud Platforms & Services","keywords":["Azure (Synapse, Data Factory)","AWS (Redshift, Glue)","Google Cloud (BigQuery, Dataflow)"]},{"name":"Data Warehousing & Lakes","keywords":["Snowflake","Azure Synapse","Amazon Redshift","Google BigQuery","Delta Lake"]},{"name":"Database Systems","keywords":["SQL Server","Oracle","PostgreSQL","MySQL","MongoDB","Cassandra"]},{"name":"Business Intelligence & Visualization","keywords":["Power BI","Tableau","Qlik Sense"]},{"name":"Programming & Scripting","keywords":["Python","PySpark","SQL","R"]},{"name":"DevOps & Agile Methodologies","keywords":["GitLab","Azure DevOps","Jenkins","Kubernetes","Scrum"]},{"name":"Data Governance & Security","keywords":["Collibra","Informatica","GDPR compliance","Data Encryption","Access Control"]}],"languages":[{"language":"English","fluency":"Fluent"}],"interests":[],"references":[],"projects":[]}