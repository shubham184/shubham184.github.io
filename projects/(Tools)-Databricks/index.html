<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Databricks | Shubham Nagar </title> <meta name="author" content="Shubham Nagar"> <meta name="description" content="Databricks Supply Chain Integration - A Case Study"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://shubham184.github.io/projects/(Tools)-Databricks/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Shubham</span> Nagar </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Databricks</h1> <p class="post-description">Databricks Supply Chain Integration - A Case Study</p> </header> <article> <h2 id="databricks-explained-simply-the-smart-city-analogy">Databricks Explained Simply: The Smart City Analogy</h2> <p>To understand Databricks in simple terms, let’s imagine it as a highly advanced, interconnected smart city. Here’s how it works:</p> <ol> <li> <p><strong>The City (Lakehouse Architecture)</strong>: Databricks is like a futuristic city that combines the best features of traditional towns (data warehouses) and sprawling suburbs (data lakes). This city can handle all types of residents (data), from organized office workers (structured data) to free-spirited artists (unstructured data).</p> </li> <li> <p><strong>Central Control Tower (Unified Analytics Platform)</strong>: At the heart of the city is a sophisticated control tower that oversees and coordinates all activities. This represents Databricks’ unified platform for data engineering, science, and analytics.</p> </li> <li> <p><strong>High-Speed Trains (Apache Spark)</strong>: The city is connected by an ultra-fast train system (Apache Spark) that can transport huge numbers of residents (process large volumes of data) quickly and efficiently.</p> </li> <li> <p><strong>Smart Homes (Delta Lake)</strong>: Residents live in smart homes (Delta Lake) that automatically organize and optimize their living spaces, similar to how Delta Lake manages and optimizes data storage.</p> </li> <li> <p><strong>Research Labs (Machine Learning Workspace)</strong>: The city has advanced research labs where scientists can experiment and develop new technologies. This represents Databricks’ machine learning capabilities.</p> </li> <li> <p><strong>City Planning Department (MLflow)</strong>: A planning department (MLflow) keeps track of all experiments and developments, ensuring that innovations can be replicated and scaled across the city.</p> </li> <li> <p><strong>Security System (Unity Catalog)</strong>: A state-of-the-art security system (Unity Catalog) ensures that only authorized residents can access different areas of the city, mirroring Databricks’ data governance and security features.</p> </li> <li> <p><strong>Power Grid (Photon Engine)</strong>: The city is powered by a highly efficient, self-optimizing power grid (Photon Engine) that provides energy exactly where and when it’s needed, similar to how Photon optimizes query processing.</p> </li> </ol> <h3 id="simple-example-a-logistics-companys-operations-system">Simple Example: A Logistics Company’s Operations System</h3> <p>Let’s say you’re running an operations system for a logistics company using Databricks:</p> <ol> <li>Different departments (warehouses, transportation, customer service) send their data to the Databricks city.</li> <li>This data is organized in the smart homes (Delta Lake), making it easy to access and analyze.</li> <li>When you need to optimize delivery routes, the research labs (Machine Learning Workspace) can develop and test algorithms using historical data.</li> <li>The high-speed trains (Apache Spark) quickly process large volumes of real-time data from delivery vehicles.</li> <li>The city planning department (MLflow) keeps track of all the route optimization experiments, allowing you to easily deploy the best models.</li> <li>If there’s a sudden surge in holiday deliveries, the city can quickly “build new neighborhoods” to handle the increased data load.</li> </ol> <p>By combining these features, Databricks provides a powerful, flexible, and easy-to-use platform for managing and analyzing large volumes of data, making it ideal for complex data environments like those found in global logistics and telecommunications industries.</p> <h2 id="situation">Situation</h2> <p>GlobalLogistics, a leading global supply chain and logistics company, was facing several challenges in managing and analyzing their vast amounts of data:</p> <ol> <li> <strong>Data Silos</strong>: Different departments were using separate systems, leading to fragmented data and inconsistent insights.</li> <li> <strong>Scalability Issues</strong>: As the company grew, their existing data infrastructure struggled to handle increasing data volumes and complex analytics.</li> <li> <strong>Real-time Processing</strong>: There was a pressing need for real-time data processing to enable quick decision-making in the fast-paced logistics industry.</li> <li> <strong>Advanced Analytics</strong>: The company wanted to leverage machine learning and AI for predictive analytics but lacked the necessary infrastructure.</li> <li> <strong>Cost Management</strong>: Maintaining multiple systems for big data processing, analytics, and machine learning was becoming increasingly expensive.</li> </ol> <h2 id="task">Task</h2> <p>As the Enterprise Data Architect, my responsibilities included:</p> <ol> <li>Designing and implementing a unified data platform that could handle batch and real-time processing.</li> <li>Ensuring the new system could scale to accommodate growing data volumes and user demands.</li> <li>Implementing a solution that would enable advanced analytics and machine learning capabilities.</li> <li>Integrating the new platform with existing supply chain systems and data sources.</li> <li>Optimizing costs while improving overall data processing and analytics performance.</li> </ol> <h2 id="action">Action</h2> <p>After careful evaluation, we chose Databricks as our unified analytics platform. Here’s how we implemented the solution:</p> <ol> <li> <p><strong>Architecture Design</strong>:</p> <ul> <li>We designed a lakehouse architecture using Databricks Delta Lake, combining the best features of data lakes and data warehouses.</li> <li>This allowed us to store both structured and unstructured data in a single platform, eliminating data silos.</li> </ul> </li> <li> <p><strong>Data Migration and Integration</strong>:</p> <ul> <li>We used Databricks’ ETL capabilities to migrate existing data from various sources into Delta Lake.</li> <li>Databricks connectors were utilized to integrate with GlobalLogistics’ ERP, TMS (Transportation Management System), and WMS (Warehouse Management System).</li> </ul> </li> <li> <p><strong>Real-time Data Processing</strong>:</p> <ul> <li>We implemented Databricks Structured Streaming to process real-time data from IoT devices, GPS trackers, and other sensors in the supply chain.</li> <li>This enabled real-time visibility into shipment status, inventory levels, and fleet performance.</li> </ul> </li> <li> <p><strong>Advanced Analytics and Machine Learning</strong>:</p> <ul> <li>We leveraged Databricks’ integration with popular ML libraries (e.g., TensorFlow, PyTorch) to develop and deploy machine learning models.</li> <li>MLflow was used for experiment tracking and model management.</li> </ul> </li> <li> <p><strong>Optimization and Performance Tuning</strong>:</p> <ul> <li>We utilized Databricks’ auto-scaling capabilities to optimize resource allocation based on workload.</li> <li>Photon, Databricks’ vectorized query engine, was enabled to accelerate SQL queries on large datasets.</li> </ul> </li> <li> <p><strong>Security Implementation</strong>:</p> <ul> <li>We implemented fine-grained access controls using Databricks’ Unity Catalog.</li> <li>Data encryption and compliance features were configured to meet industry standards.</li> </ul> </li> <li> <p><strong>Training and Documentation</strong>:</p> <ul> <li>Comprehensive training sessions were conducted for data scientists, analysts, and engineers.</li> <li>We created detailed documentation covering best practices, data dictionary, and common use cases.</li> </ul> </li> </ol> <h2 id="result">Result</h2> <p>The implementation of Databricks at GlobalLogistics yielded significant benefits:</p> <ol> <li> <p><strong>Unified Data Platform</strong>: Achieved a single source of truth for all supply chain data, eliminating data silos and inconsistencies.</p> </li> <li> <p><strong>Improved Scalability</strong>: Successfully scaled data processing from 10TB to 100TB within a year without performance degradation.</p> </li> <li> <p><strong>Real-time Insights</strong>: Reduced data processing latency from hours to minutes, enabling real-time decision-making in logistics operations.</p> </li> <li> <p><strong>Advanced Analytics Capabilities</strong>:</p> <ul> <li>Implemented predictive maintenance models, reducing vehicle downtime by 30%.</li> <li>Developed demand forecasting models, improving inventory accuracy by 25%.</li> </ul> </li> <li> <p><strong>Cost Optimization</strong>: Realized a 35% reduction in overall data infrastructure costs due to the consolidation of multiple systems into Databricks.</p> </li> <li> <p><strong>Enhanced Collaboration</strong>: Data scientists, analysts, and engineers could now collaborate seamlessly on the same platform, improving productivity by 40%.</p> </li> <li> <p><strong>Improved Query Performance</strong>: Achieved a 60% reduction in average query execution time for complex supply chain analytics.</p> </li> <li> <p><strong>Better Resource Utilization</strong>: Auto-scaling and workload optimization led to a 50% improvement in cluster utilization.</p> </li> </ol> <h2 id="real-world-examples-of-databricks-usage-in-the-project">Real-world Examples of Databricks Usage in the Project</h2> <ol> <li> <p><strong>Predictive Maintenance for Fleet Vehicles</strong>:</p> <ul> <li>Use Case: Predicting maintenance needs for GlobalLogistics’ delivery fleet.</li> <li>Implementation: We used Databricks to analyze historical maintenance records, real-time sensor data from vehicles, and weather data. Machine learning models were developed using Databricks’ MLflow to predict potential failures.</li> <li>Result: Reduced unplanned vehicle downtime by 35%, resulting in significant cost savings and improved delivery reliability.</li> </ul> </li> <li> <p><strong>Dynamic Route Optimization</strong>:</p> <ul> <li>Use Case: Optimizing delivery routes in real-time based on traffic, weather, and order data.</li> <li>Implementation: We used Databricks Structured Streaming to process real-time GPS data from vehicles, traffic APIs, and weather services. This data was combined with order information to dynamically adjust routes.</li> <li>Result: Achieved a 15% reduction in fuel costs and a 20% improvement in on-time deliveries.</li> </ul> </li> <li> <p><strong>Demand Forecasting and Inventory Optimization</strong>:</p> <ul> <li>Use Case: Improving the accuracy of demand forecasts to optimize inventory levels across multiple warehouses.</li> <li>Implementation: Historical sales data, promotional events, and external economic indicators were analyzed using Databricks’ time series forecasting capabilities. The resulting models were deployed using MLflow.</li> <li>Result: Improved forecast accuracy by 30%, leading to a 20% reduction in excess inventory costs and a 15% improvement in product availability.</li> </ul> </li> <li> <p><strong>Supply Chain Network Optimization</strong>:</p> <ul> <li>Use Case: Optimizing the placement of distribution centers and routing strategies.</li> <li>Implementation: We used Databricks to analyze vast amounts of historical shipment data, customer locations, and transportation costs. Graph analytics were performed to identify optimal network configurations.</li> <li>Result: Identified opportunities to optimize the supply chain network, potentially reducing transportation costs by 18% and improving average delivery times by 12%.</li> </ul> </li> <li> <p><strong>Real-time Shipment Tracking and Anomaly Detection</strong>:</p> <ul> <li>Use Case: Providing real-time visibility into shipment status and detecting potential issues.</li> <li>Implementation: We implemented a streaming pipeline in Databricks to process real-time data from IoT devices attached to shipments. Machine learning models were used to detect anomalies in transit times or environmental conditions.</li> <li>Result: Improved shipment visibility, reduced loss and damage rates by 25%, and enhanced customer satisfaction through proactive issue resolution.</li> </ul> </li> </ol> <p>These real-world examples demonstrate how Databricks’ capabilities were leveraged to address specific supply chain challenges at GlobalLogistics, resulting in significant improvements across various aspects of their operations.</p> <h2 id="limitations-and-future-considerations">Limitations and Future Considerations</h2> <p>While Databricks significantly improved GlobalLogistics’ data management and analytics capabilities, some limitations were noted:</p> <ol> <li> <p><strong>Learning Curve</strong>: Some team members initially struggled with the concept of the lakehouse architecture and the Spark programming model.</p> </li> <li> <p><strong>Cost Management</strong>: While overall costs decreased, careful monitoring was required to prevent unexpected spikes due to inefficient queries or poorly optimized workloads.</p> </li> <li> <p><strong>Data Governance</strong>: As the volume of data and number of users grew, maintaining consistent data governance policies became challenging.</p> </li> </ol> <p>Future considerations for enhancing Databricks’ use in GlobalLogistics include:</p> <ol> <li>Exploring Databricks’ AutoML capabilities to democratize machine learning across the organization.</li> <li>Implementing Databricks’ Genomics capabilities for more advanced performance optimization.</li> <li>Expanding the use of Delta Sharing for secure and governed data sharing with partners and customers.</li> <li>Investigating Databricks’ SQL warehouses for providing a more familiar SQL-based interface to business analysts.</li> </ol> <p>In conclusion, the implementation of Databricks has transformed GlobalLogistics’ data infrastructure, enabling advanced analytics, real-time insights, and significant cost savings. As the company continues to grow and evolve, Databricks will play a crucial role in driving data-driven decision making across the supply chain.</p> <h2 id="10-real-life-use-cases-related-to-telecommunications">10 Real-life Use Cases Related to Telecommunications</h2> <p>In addition to the supply chain-specific applications, GlobalLogistics leveraged Databricks to address various telecommunications-related challenges within their operations. Here are 10 real-world use cases that demonstrate the versatility of Databricks in handling telecom data and analytics:</p> <ol> <li> <p><strong>Network Performance Optimization</strong>:</p> <ul> <li>Use Case: Analyzing network performance data to optimize GlobalLogistics’ global communication infrastructure.</li> <li>Implementation: We used Databricks to ingest and process large volumes of network log data in real-time. Machine learning models were developed to predict network congestion and automatically adjust routing.</li> <li>Result: Achieved a 25% improvement in network throughput and reduced downtime by 40%.</li> </ul> </li> <li> <p><strong>Customer Churn Prediction</strong>:</p> <ul> <li>Use Case: Predicting and preventing churn among GlobalLogistics’ B2B telecom service customers.</li> <li>Implementation: We consolidated customer interaction data, service usage patterns, and historical churn data in Delta Lake. Machine learning models were built using Databricks’ MLflow to predict potential churners.</li> <li>Result: Reduced customer churn by 15% through targeted retention campaigns.</li> </ul> </li> <li> <p><strong>5G Network Planning</strong>:</p> <ul> <li>Use Case: Optimizing the rollout of 5G infrastructure to support GlobalLogistics’ IoT and edge computing initiatives.</li> <li>Implementation: We used Databricks to analyze geographical data, existing network usage patterns, and projected data demands. Graph analytics were employed to determine optimal tower placements.</li> <li>Result: Developed a cost-effective 5G rollout plan that promised 95% coverage of critical areas while minimizing infrastructure costs by 20%.</li> </ul> </li> <li> <p><strong>Anomaly Detection in Call Data Records (CDRs)</strong>:</p> <ul> <li>Use Case: Identifying fraudulent activities and billing errors in GlobalLogistics’ telecommunications services.</li> <li>Implementation: We implemented a streaming pipeline in Databricks to process CDRs in real-time. Machine learning models were used to detect anomalies in call patterns and usage.</li> <li>Result: Reduced fraudulent activities by 60% and improved billing accuracy by 30%.</li> </ul> </li> <li> <p><strong>Predictive Maintenance for Telecom Equipment</strong>:</p> <ul> <li>Use Case: Predicting maintenance needs for GlobalLogistics’ telecommunications infrastructure.</li> <li>Implementation: We used Databricks to analyze IoT sensor data from telecom equipment along with historical maintenance records. Predictive models were developed to forecast potential failures.</li> <li>Result: Reduced unplanned downtime of critical communication equipment by 50%, ensuring more reliable operations.</li> </ul> </li> <li> <p><strong>Spectrum Utilization Optimization</strong>:</p> <ul> <li>Use Case: Optimizing the use of available spectrum in GlobalLogistics’ wireless communications.</li> <li>Implementation: We used Databricks’ real-time processing capabilities to analyze spectrum usage data. Machine learning models were developed to dynamically allocate spectrum based on demand.</li> <li>Result: Improved spectrum efficiency by 35%, allowing for higher data throughput without additional spectrum acquisition.</li> </ul> </li> <li> <p><strong>Voice of Customer Analytics</strong>:</p> <ul> <li>Use Case: Analyzing customer feedback and support calls to improve service quality.</li> <li>Implementation: We used Databricks’ natural language processing capabilities to analyze transcribed customer calls and written feedback. Sentiment analysis and topic modeling were performed to identify key areas for improvement.</li> <li>Result: Improved customer satisfaction scores by 20% through targeted service improvements.</li> </ul> </li> <li> <p><strong>Network Capacity Planning</strong>:</p> <ul> <li>Use Case: Forecasting future network capacity needs to support growing data demands in GlobalLogistics’ operations.</li> <li>Implementation: Historical network usage data, growth projections, and planned operational expansions were analyzed in Databricks to forecast future capacity needs.</li> <li>Result: Developed a 5-year network capacity plan that optimized infrastructure investments, avoiding over-provisioning while ensuring 99.99% network availability.</li> </ul> </li> <li> <p><strong>IoT Device Management and Analytics</strong>:</p> <ul> <li>Use Case: Managing and analyzing data from millions of IoT devices used in tracking shipments and monitoring cargo conditions.</li> <li>Implementation: We used Databricks’ capabilities to ingest and process massive volumes of IoT data in real-time. Machine learning models were developed to predict device failures and optimize battery life.</li> <li>Result: Improved IoT device lifespan by 30% and reduced data transmission costs by 25% through optimized protocols.</li> </ul> </li> <li> <p><strong>Regulatory Compliance Reporting</strong>:</p> <ul> <li>Use Case: Automating the generation of regulatory reports for telecom operations across different regions.</li> <li>Implementation: We used Databricks to aggregate data from various operational systems. Automated workflows were set up to generate compliance reports, with Delta Lake ensuring data consistency and auditability.</li> <li>Result: Reduced time spent on compliance reporting by 70% while improving accuracy and consistency of reports.</li> </ul> </li> </ol> <p>These telecommunications-focused use cases demonstrate how GlobalLogistics leveraged Databricks’ capabilities to address not only supply chain challenges but also the complex data management and analytics needs of their underlying telecommunications infrastructure. By integrating telecom data with supply chain operations data in Databricks, GlobalLogistics was able to achieve a more holistic view of their operations, leading to improved efficiency, cost savings, and enhanced service quality across their global logistics network.</p> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Shubham Nagar. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-projects",title:"projects",description:"A growing collection of my data projects.",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-cv",title:"cv",description:"",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"post-migrating-from-tableau-to-power-bi-a-comprehensive-guide",title:'Migrating from Tableau to Power BI: A Comprehensive Guide <svg width="1.2rem" height="1.2rem" top=".5rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"",section:"Posts",handler:()=>{window.open("https://medium.com/mind-and-machine/migrating-from-tableau-to-power-bi-a-comprehensive-guide-b6e4929e1ea3?source=rss-5ad90eb46828------2","_blank")}},{id:"post-discovering-anomalies-with-mad-the-secret-sauce-for-accurate-data-analysis",title:'Discovering Anomalies with MAD: The Secret Sauce for Accurate Data Analysis <svg width="1.2rem" height="1.2rem" top=".5rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"",section:"Posts",handler:()=>{window.open("https://medium.com/mind-and-machine/discovering-anomalies-with-mad-the-secret-sauce-for-accurate-data-analysis-ed1c7909e2bf?source=rss-5ad90eb46828------2","_blank")}},{id:"post-harnessing-agentic-rag-and-graph-based-metadata-filtering-for-enhanced-information-retrieval",title:'Harnessing Agentic RAG and Graph-Based Metadata Filtering for Enhanced Information Retrieval <svg width="1.2rem" height="1.2rem" top=".5rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"",section:"Posts",handler:()=>{window.open("https://medium.com/mind-and-machine/harnessing-agentic-rag-and-graph-based-metadata-filtering-for-enhanced-information-retrieval-5e4fc88dcdc0?source=rss-5ad90eb46828------2","_blank")}},{id:"post-the-critical-role-of-red-teaming-in-ai-development",title:'The Critical Role of Red Teaming in AI Development <svg width="1.2rem" height="1.2rem" top=".5rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"",section:"Posts",handler:()=>{window.open("https://medium.com/mind-and-machine/the-critical-role-of-red-teaming-in-ai-development-8a1b393cfc51?source=rss-5ad90eb46828------2","_blank")}},{id:"post-who-am-i",title:'Who am I? <svg width="1.2rem" height="1.2rem" top=".5rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"",section:"Posts",handler:()=>{window.open("https://medium.com/@mail.shubhamnagar/who-am-i-f6810254e1ba?source=rss-5ad90eb46828------2","_blank")}},{id:"post-trust-or-distrust-bridging-ai-and-blockchain",title:'Trust or Distrust: Bridging AI and Blockchain <svg width="1.2rem" height="1.2rem" top=".5rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"",section:"Posts",handler:()=>{window.open("https://medium.com/mind-and-machine/trust-or-distrust-bridging-ai-and-blockchain-659c5760ef6?source=rss-5ad90eb46828------2","_blank")}},{id:"post-ai-technologies-in-the-new-era-catalysts-or-hindrances-for-the-rpa-industry",title:'AI Technologies in the New Era: Catalysts or Hindrances for the RPA Industry?... <svg width="1.2rem" height="1.2rem" top=".5rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"",section:"Posts",handler:()=>{window.open("https://medium.com/@mail.shubhamnagar/ai-technologies-in-the-new-era-catalysts-or-hindrances-for-the-rpa-industry-e3c083950ced?source=rss-5ad90eb46828------2","_blank")}},{id:"news-a-simple-inline-announcement",title:"A simple inline announcement.",description:"",section:"News"},{id:"news-a-long-announcement-with-details",title:"A long announcement with details",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_2/"}},{id:"news-a-simple-inline-announcement-with-markdown-emoji-sparkles-smile",title:'A simple inline announcement with Markdown emoji! <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20">',description:"",section:"News"},{id:"projects-advanced-supply-chain-analytics-platform-optimizing-global-logistics-with-real-time-data",title:"Advanced Supply Chain Analytics Platform - Optimizing Global Logistics with Real-time Data",description:"Developed a cutting-edge supply chain analytics platform integrating real-time IoT data, predictive analytics, and interactive visualizations to optimize global logistics operations.",section:"Projects",handler:()=>{window.location.href="/projects/(Analytics)-advanced-data-visualization-project/"}},{id:"projects-data-modeling-for-e-commerce-reducing-redundancy-and-improving-customer-insights",title:"Data Modeling for E-commerce - Reducing Redundancy and Improving Customer Insights",description:"A comprehensive overhaul of an e-commerce platform's data model, resulting in 40% reduced data redundancy and 25% improved customer segmentation accuracy.",section:"Projects",handler:()=>{window.location.href="/projects/(Analytics)-ecommerce-data-modeling/"}},{id:"projects-snowflake-data-warehousing-project-optimizing-analytics-for-scale",title:"Snowflake Data Warehousing Project - Optimizing Analytics for Scale",description:"Implemented a Snowflake data warehouse solution, achieving a 40% reduction in query times and enabling real-time analytics across diverse data sources for a rapidly growing e-commerce company.",section:"Projects",handler:()=>{window.location.href="/projects/(Analytics)-snowflake-project/"}},{id:"projects-data-architecture-strategy-data-silos-ai-implementaion",title:"Data Architecture Strategy - Data Silos - AI Implementaion",description:"Enterprise Data Architect Case Study - Enabling AI Integration in Global Logistics",section:"Projects",handler:()=>{window.location.href="/projects/(DA)-AI-Implementaion/"}},{id:"projects-comprehensive-data-architecture-strategy-for-global-supply-chain-and-logistics",title:"Comprehensive Data Architecture Strategy for Global Supply Chain and Logistics",description:"Designed and implemented a comprehensive data architecture strategy for a global supply chain and logistics customer, improving data accessibility by 35% and streamlining reporting processes across their international operations.",section:"Projects",handler:()=>{window.location.href="/projects/(DA)-comprehensive-data-architecture-strategy/"}},{id:"projects-data-lake-to-data-fabric-modernizing-data-architecture-for-a-multinational-corporation",title:"Data Lake to Data Fabric - Modernizing Data Architecture for a Multinational Corporation...",description:"Transitioning from a traditional data lake to a data fabric approach, improving data accessibility, governance, and analytics agility",section:"Projects",handler:()=>{window.location.href="/projects/(DA)-data-fabric-case-study/"}},{id:"projects-data-pipeline-management-with-apache-spark-and-talend",title:"Data Pipeline Management with Apache Spark and Talend",description:"Designed and managed data pipelines for data validation, transformation, and cleaning using Apache Spark and Talend, ensuring the highest quality and reliability of data across the organization.",section:"Projects",handler:()=>{window.location.href="/projects/(DA)-data-pipeline-management/"}},{id:"projects-so-what-data-should-you-manage-as-master-data",title:"So, What Data Should You Manage as Master Data?",description:"Understanding Master Data Management for telco",section:"Projects",handler:()=>{window.location.href="/projects/(DG)-MDM-Telco/"}},{id:"projects-initiating-supply-chain-transparency-with-mdm",title:"Initiating Supply Chain Transparency with MDM",description:"EcoTrace Solutions - Initiating Supply Chain Transparency with MDM",section:"Projects",handler:()=>{window.location.href="/projects/(DG)-MDM-experience/"}},{id:"projects-revolutionizing-telecom-analytics-oss-bss-data-governance-and-warehousing",title:"Revolutionizing Telecom Analytics - OSS/BSS Data Governance and Warehousing",description:"A comprehensive data governance and analytics solution for a leading telecom company",section:"Projects",handler:()=>{window.location.href="/projects/(DG)-OSS-BSS/"}},{id:"projects-enhancing-metadata-management-using-collibra-business-glossary",title:"Enhancing Metadata Management Using Collibra Business Glossary",description:"Implemented a robust metadata management system using Collibra and integrated it with Mega HOPEX for improved data governance and consistency across the organization.",section:"Projects",handler:()=>{window.location.href="/projects/(DG)-collibra-metadata-case-study/"}},{id:"projects-revolutionizing-supply-chain-data-governance-at-globallogistics",title:"Revolutionizing Supply Chain Data Governance at GlobalLogistics",description:"Implementing enterprise-wide data standards and quality measures to streamline global logistics operations",section:"Projects",handler:()=>{window.location.href="/projects/(DG)-data-governance-collibra/"}},{id:"projects-pioneering-data-governance-in-fashion-supply-chain-transparency",title:"Pioneering Data Governance in Fashion Supply Chain Transparency",description:"Pioneering Data Governance in Fashion Supply Chain Transparency",section:"Projects",handler:()=>{window.location.href="/projects/(DG)-data-governance-exp/"}},{id:"projects-implementing-data-governance-a-journey-from-silos-to-standardization",title:"Implementing Data Governance - A Journey from Silos to Standardization",description:"Transforming organizational data management through strategic governance initiatives",section:"Projects",handler:()=>{window.location.href="/projects/(DG)-implementing-data-governance/"}},{id:"projects-mdm-amp-dg-journey",title:"MDM & DG Journey",description:"Understanding Master Data Management for telco",section:"Projects",handler:()=>{window.location.href="/projects/(DG)-mdm-experinced-final/"}},{id:"projects-enhancing-regulatory-compliance-and-data-governance-in-global-supply-chain-operations",title:"Enhancing Regulatory Compliance and Data Governance in Global Supply Chain Operations",description:"A case study on implementing Collibra and Mega HOPEX to streamline compliance and data management for GlobalLogistics",section:"Projects",handler:()=>{window.location.href="/projects/(DG)-regulatory-compliance/"}},{id:"projects-data-integration-project-telco-colibra",title:"Data Integration Project (Telco) - Colibra",description:"Implemented a comprehensive data integration solution for a global logistics company using Collibra and Mega HOPEX, resulting in improved operational efficiency and data-driven decision making.",section:"Projects",handler:()=>{window.location.href="/projects/(DI)-colibra-data-integration-telco/"}},{id:"projects-data-integration-project-supply-chain-colibra",title:"Data Integration Project (Supply Chain) - Colibra",description:"Implemented a comprehensive data integration solution for a global logistics company using Collibra and Mega HOPEX, resulting in improved operational efficiency and data-driven decision making.",section:"Projects",handler:()=>{window.location.href="/projects/(DI)-colibra-data-integration/"}},{id:"projects-esg-compliance-regional-telecom",title:"ESG Compliance - Regional Telecom",description:"A comprehensive data architecture overhaul to meet emerging ESG standards and optimize telecom operations in Belgium",section:"Projects",handler:()=>{window.location.href="/projects/(DI)-esg-telco/"}},{id:"projects-esg-compliance-supply-chain",title:"ESG Compliance - Supply Chain",description:"A comprehensive data architecture overhaul to meet emerging ESG standards and optimize supply chain operations",section:"Projects",handler:()=>{window.location.href="/projects/(DI)-esg/"}},{id:"projects-modernizing-supply-chain-integration-at-globallogistics",title:"Modernizing Supply Chain Integration at GlobalLogistics",description:"Implementing cutting-edge integration technologies to streamline global supply chain operations",section:"Projects",handler:()=>{window.location.href="/projects/(DI)-modern-supply-chain/"}},{id:"projects-modernizing-telco-integration-at-belgicom",title:"Modernizing Telco Integration at BelgiCom",description:"Proposed implementation of cutting-edge integration technologies to streamline telecom operations",section:"Projects",handler:()=>{window.location.href="/projects/(DI)-modern-telco-integration/"}},{id:"projects-streamlining-supply-chain-data-architecture-at-globallogistics",title:"Streamlining Supply Chain Data Architecture at GlobalLogistics",description:"A comprehensive data integration project that revolutionized GlobalLogistics' supply chain operations",section:"Projects",handler:()=>{window.location.href="/projects/(DI)-streamlining-supply-chain-architecture/"}},{id:"projects-scalable-real-time-data-platform-for-e-commerce",title:"Scalable Real-Time Data Platform for E-Commerce",description:"Implemented a high-performance data platform using API-first design, Kafka, FastAPI, and Airflow for an e-commerce giant, enabling real-time personalization and handling over 100,000 requests per second.",section:"Projects",handler:()=>{window.location.href="/projects/(Messaging)-realtime-data-platform/"}},{id:"projects-databricks",title:"Databricks",description:"Databricks Supply Chain Integration - A Case Study",section:"Projects",handler:()=>{window.location.href="/projects/(Tools)-Databricks/"}},{id:"projects-netcracker-oss",title:"NetCracker OSS",description:"NetCracker for Network Management",section:"Projects",handler:()=>{window.location.href="/projects/(Tools)-Netcracker/"}},{id:"projects-snowflake",title:"Snowflake",description:"Snowflake Supply Chain Integration - A Case Study",section:"Projects",handler:()=>{window.location.href="/projects/(Tools)-Snowflake/"}},{id:"projects-talend-data-integration",title:"Talend Data Integration",description:"Talend How and Why",section:"Projects",handler:()=>{window.location.href="/projects/(Tools)-Talend/"}},{id:"projects-apache-kafka",title:"Apache kafka",description:"Kafka How and Why",section:"Projects",handler:()=>{window.location.href="/projects/(Tools)-apache-kafka/"}},{id:"projects-apache-spark",title:"Apache spark",description:"Spark How and Why",section:"Projects",handler:()=>{window.location.href="/projects/(Tools)-apche-spark/"}},{id:"projects-aws-sqs",title:"AWS SQS",description:"SQS How and Why",section:"Projects",handler:()=>{window.location.href="/projects/(Tools)-aws-sqs/"}},{id:"projects-how-collibra-and-leanix-complement-each-other-in-telecom",title:"How Collibra and LeanIX Complement Each Other in Telecom",description:"How Collibra and LeanIX Complement Each Other in Telecom",section:"Projects",handler:()=>{window.location.href="/projects/(Tools)-collibra-plus-leanix/"}},{id:"projects-collibra",title:"Collibra",description:"Collibra Explained Simply",section:"Projects",handler:()=>{window.location.href="/projects/(Tools)-collibra/"}},{id:"projects-sap-leanix",title:"SAP LeanIX",description:"LeanIX Explained Simply",section:"Projects",handler:()=>{window.location.href="/projects/(Tools)-leanix/"}},{id:"projects-mulesoft",title:"Mulesoft",description:"A deep dive into how MuleSoft Anypoint Platform transformed global supply chain operations",section:"Projects",handler:()=>{window.location.href="/projects/(Tools)-mulesoft/"}},{id:"projects-sqs-vs-kafka",title:"SQS vs Kafka",description:"Complementing Kafka with SQS",section:"Projects",handler:()=>{window.location.href="/projects/(Tools)-sqs-kafka/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%6D%61%69%6C.%73%68%75%62%68%61%6D%6E%61%67%61%72@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/shubham184","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/shubham-nagar-222497151","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>