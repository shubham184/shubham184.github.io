<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Proposed Solution - Revolutionizing Telecom Operations with SQS, Kafka, and MuleSoft | Shubham Nagar </title> <meta name="author" content="Shubham Nagar"> <meta name="description" content="A forward-looking plan to transform data flows and system integration for enhanced customer experience, operational efficiency, and regulatory compliance"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://shubham184.github.io/projects/(Messaging)-Telco-use-case/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Shubham</span> Nagar </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Proposed Solution - Revolutionizing Telecom Operations with SQS, Kafka, and MuleSoft</h1> <p class="post-description">A forward-looking plan to transform data flows and system integration for enhanced customer experience, operational efficiency, and regulatory compliance</p> </header> <article> <h2 id="situation">Situation</h2> <p><strong>TelecomCo</strong>, a major telecommunications provider serving over 50 million customers across multiple countries, is facing significant challenges in managing its complex network infrastructure and maintaining efficient operations while adhering to strict regulatory requirements. As an Enterprise Data Architect, I have been brought in to address several critical issues:</p> <ul> <li> <p><strong>Delayed Customer Requests</strong>: Service activations and plan changes are taking up to 48 hours to propagate through systems, leading to customer frustration and increased support calls.</p> <ul> <li> <em>Example</em>: A customer requesting a 5G plan upgrade often has to wait two full days before the new service is activated, resulting in numerous complaint calls to customer service.</li> </ul> </li> <li> <p><strong>Batch Processing of CDRs</strong>: Call Detail Records (CDRs) are processed in nightly batches, resulting in delayed billing and inaccurate real-time usage insights.</p> <ul> <li> <em>Example</em>: A customer on a pay-as-you-go plan can’t see their latest calls or data usage reflected in their account until the next day, leading to potential overspending and bill shock.</li> </ul> </li> <li> <p><strong>Fragmented Integration</strong>: The lack of seamless integration between legacy OSS/BSS systems and modern cloud applications is leading to data inconsistencies and operational inefficiencies.</p> <ul> <li> <em>Example</em>: Customer address updates made in the CRM system aren’t automatically reflected in the billing system, causing invoices to be sent to outdated addresses.</li> </ul> </li> <li> <p><strong>Inefficient Network Monitoring</strong>: TelecomCo is struggling to monitor network performance in real-time, often resulting in delayed responses to outages and degraded service quality.</p> <ul> <li> <em>Example</em>: A cell tower malfunction in a busy urban area can go unnoticed for hours, affecting thousands of customers before being detected and addressed.</li> </ul> </li> <li> <p><strong>Regulatory Compliance Challenges</strong>: TelecomCo is struggling to meet evolving data privacy regulations and industry-specific requirements.</p> <ul> <li> <em>Example</em>: Ensuring GDPR compliance for EU customers while maintaining the ability to perform lawful intercepts as required by local telecommunications laws is becoming increasingly complex.</li> </ul> </li> </ul> <h2 id="task">Task</h2> <p>As the lead Enterprise Data Architect for this project, my primary responsibilities will be to:</p> <ol> <li>Design a comprehensive data architecture leveraging <strong>Amazon SQS</strong>, <strong>Apache Kafka</strong>, and <strong>MuleSoft</strong> to address TelecomCo’s challenges while ensuring regulatory compliance.</li> <li>Develop a detailed implementation plan to integrate these technologies with existing OSS/BSS systems.</li> <li>Ensure the new architecture can handle the scale and complexity of TelecomCo’s operations, processing millions of transactions daily.</li> <li>Create a roadmap for migrating from batch processing to real-time data streams for critical operations.</li> <li>Establish metrics and KPIs to measure the success of the new architecture.</li> <li>Design a future-proof architecture capable of supporting emerging technologies like <strong>5G</strong> and <strong>IoT</strong>.</li> </ol> <h2 id="proposed-action-plan">Proposed Action Plan</h2> <p>To address TelecomCo’s challenges, I propose to lead the design and implementation of a new data architecture:</p> <ol> <li> <p><strong>Data Flow Mapping with MuleSoft</strong></p> <ul> <li>We will conduct extensive workshops with key stakeholders to map out data flows between CRM, provisioning, billing, and OSS systems.</li> <li>We’ll design API-led connectivity using MuleSoft, creating reusable assets for common integration patterns.</li> <li> <em>Example</em>: We’ll create a “<strong>Customer 360 API</strong>” that will aggregate data from multiple systems, providing a single source of truth for customer information. <ul> <li> <em>Implementation detail</em>: We’ll use MuleSoft’s <strong>DataWeave</strong> to transform and normalize customer data from legacy systems into a standardized JSON format, enabling easy consumption by modern applications while maintaining data lineage for compliance purposes.</li> </ul> </li> </ul> </li> <li> <p><strong>Queue-Based Communication with Amazon SQS</strong></p> <ul> <li>We’ll implement SQS queues for asynchronous processing of customer service requests.</li> <li>We’ll set up dead-letter queues to handle failed messages, ensuring no customer requests are lost.</li> <li> <em>Example</em>: When a customer requests a plan upgrade, the request will be queued in SQS, allowing the CRM to acknowledge receipt immediately while backend systems process the change asynchronously. <ul> <li> <em>Implementation detail</em>: We’ll create separate SQS queues for different types of requests (e.g., “<strong>PlanChangeQueue</strong>”, “<strong>NewServiceQueue</strong>”) to optimize processing and prioritization. We’ll implement encryption at rest and in transit for all SQS queues to ensure data security.</li> </ul> </li> </ul> </li> <li> <p><strong>Real-Time Streaming with Apache Kafka</strong></p> <ul> <li>We’ll design a Kafka-based streaming architecture for real-time ingestion of network events, usage data, and CDRs.</li> <li>We’ll implement Kafka Connect to ingest data from legacy systems that can’t be easily modified.</li> <li> <em>Example</em>: We’ll set up a Kafka topic for real-time CDR streaming, allowing for immediate usage updates and real-time billing. <ul> <li> <em>Implementation detail</em>: We’ll use <strong>Kafka Streams</strong> to process CDRs in real-time, aggregating usage data per customer and updating billing information every minute instead of nightly batches. We’ll implement data masking for sensitive fields to ensure GDPR compliance.</li> </ul> </li> <li>We’ll extend Kafka’s role beyond CDRs: <ul> <li> <em>Network event monitoring</em>: We’ll create a “<strong>NetworkEvents</strong>” Kafka topic to stream real-time metrics from cell towers and network equipment, enabling proactive issue detection.</li> <li> <em>Proactive customer notifications</em>: We’ll implement a “<strong>CustomerAlerts</strong>” Kafka topic to trigger real-time notifications when customers approach data usage thresholds or experience service issues.</li> </ul> </li> </ul> </li> <li> <p><strong>System Integration with MuleSoft</strong></p> <ul> <li>We’ll utilize MuleSoft’s Anypoint Platform to create a unified API layer, exposing legacy system functionalities as modern REST APIs.</li> <li>We’ll implement data transformation and normalization within MuleSoft to ensure consistency across systems.</li> <li> <em>Example</em>: We’ll create an “<strong>Order Management API</strong>” that will orchestrate the entire order fulfillment process across multiple systems, from CRM to provisioning to billing. <ul> <li> <em>Implementation detail</em>: We’ll implement a MuleSoft flow that coordinates the provisioning process, triggering actions in the OSS, updating the BSS, and sending confirmation back to the CRM, all exposed as a single RESTful endpoint. We’ll integrate with Kafka to publish events at each stage of the order process.</li> </ul> </li> </ul> </li> <li> <p><strong>Real-Time Analytics and Monitoring</strong></p> <ul> <li>We’ll leverage Kafka Streams for real-time network performance analytics.</li> <li>We’ll implement a real-time dashboard for network operations, showcasing key metrics like bandwidth utilization and service quality indicators.</li> <li> <em>Example</em>: We’ll create a real-time heat map of network performance across all cell towers, updating every 30 seconds. <ul> <li> <em>Implementation detail</em>: We’ll use Kafka Streams to process raw network telemetry data, aggregating metrics by geographic area and severity, then pushing results to a WebSocket API for live dashboard updates. We’ll integrate with <strong>Prometheus</strong> for metric collection and <strong>Grafana</strong> for visualization.</li> </ul> </li> </ul> </li> <li> <p><strong>Data Consistency and Synchronization</strong></p> <ul> <li>We’ll use MuleSoft to implement a data synchronization layer, ensuring customer profiles and service plans are consistent across all systems.</li> <li>We’ll implement event-driven architecture using Kafka to propagate changes in real-time across the ecosystem.</li> <li> <em>Example</em>: When a customer’s address is updated in the CRM, an event will be published to Kafka, triggering updates in billing, shipping, and network provisioning systems. <ul> <li> <em>Implementation detail</em>: We’ll create a “<strong>CustomerProfileChanged</strong>” Kafka topic. Systems subscribed to this topic will receive updates and process them according to their specific needs (e.g., billing system updates invoice address, network system updates service area). We’ll implement a correlation ID system to track changes across systems for auditing purposes.</li> </ul> </li> </ul> </li> <li> <p><strong>Scalability and Reliability Measures</strong></p> <ul> <li>We’ll design the Kafka cluster for high availability, with multi-zone deployment and automated failover.</li> <li>We’ll implement auto-scaling for SQS based on queue length to handle traffic spikes during peak hours or promotional events.</li> <li> <em>Example</em>: During a major product launch, the system will automatically scale to handle a 300% increase in customer service requests without performance degradation. <ul> <li> <em>Implementation detail</em>: We’ll set up AWS Auto Scaling groups for Kafka brokers and configure SQS to trigger scaling events based on queue depth metrics, ensuring processing capacity matches incoming request volume. We’ll implement Kafka’s rack awareness feature to ensure data replication across different availability zones for fault tolerance.</li> </ul> </li> </ul> </li> <li> <p><strong>Security and Compliance</strong></p> <ul> <li>We’ll implement end-to-end encryption for data in transit and at rest.</li> <li>We’ll set up detailed audit logging using Kafka to track all data access and modifications, ensuring compliance with telecom regulations.</li> <li> <em>Example</em>: We’ll create a comprehensive audit trail of all changes to customer data, including who made the change, when, and from which system. <ul> <li> <em>Implementation detail</em>: We’ll implement a Kafka topic for audit logs, with each message containing detailed metadata about data changes. This will then be integrated with a security information and event management (SIEM) system for real-time monitoring and alerting.</li> </ul> </li> <li> <em>Regulatory compliance</em>: <ul> <li>We’ll implement data anonymization and pseudonymization techniques in Kafka Streams for GDPR compliance.</li> <li>We’ll create a separate, highly secure Kafka topic for lawful intercept data, with strict access controls and comprehensive auditing.</li> </ul> </li> </ul> </li> <li> <p><strong>Performance Metrics and Monitoring</strong></p> <ul> <li>We’ll implement comprehensive monitoring across the entire architecture.</li> <li> <em>Example</em>: We’ll set up real-time alerting for SQS queue depths, Kafka consumer lag, and MuleSoft API response times. <ul> <li> <em>Implementation detail</em>: We’ll use Prometheus to collect metrics from Kafka, SQS, and MuleSoft. We’ll set up Grafana dashboards for real-time visualization of system health and performance. We’ll configure alerts to trigger automated scaling events or notify operations teams of potential issues.</li> </ul> </li> </ul> </li> <li> <p><strong>Future-Proofing for 5G and IoT</strong></p> <ul> <li>We’ll design the architecture with extensibility in mind to support future 5G and IoT use cases.</li> <li> <em>Example</em>: We’ll create a scalable data ingestion pipeline capable of handling the high-volume, low-latency requirements of 5G network slicing. <ul> <li> <em>Implementation detail</em>: We’ll implement Kafka Streams applications capable of processing high-throughput 5G data streams. We’ll design MuleSoft APIs with extensible data models to accommodate future IoT device types and data formats.</li> </ul> </li> </ul> </li> </ol> <h2 id="expected-results">Expected Results</h2> <p>The implementation of this new architecture is expected to yield significant improvements across TelecomCo’s operations:</p> <ul> <li> <p><strong>Faster Customer Request Processing</strong>: Service activation times should reduce from 48 hours to under 15 minutes, resulting in a 35% decrease in related customer complaints.</p> <ul> <li> <em>Example</em>: 5G plan upgrades, which previously took two days, will be activated within minutes of customer requests.</li> </ul> </li> <li> <p><strong>Real-Time Billing Accuracy</strong>: By streaming CDRs in real-time, billing accuracy should improve by 99.9%, and customers will be able to view their usage and charges immediately.</p> <ul> <li> <em>Example</em>: Pay-as-you-go customers will see their balance updated within seconds of ending a call or data session.</li> </ul> </li> <li> <p><strong>Enhanced Network Monitoring</strong>: Network issues should be detected and resolved 75% faster, leading to a 30% reduction in service outages.</p> <ul> <li> <em>Example</em>: A cell tower malfunction that previously took 4 hours to detect will be identified and addressed within 15 minutes.</li> </ul> </li> <li> <p><strong>Improved Data Consistency</strong>: Data discrepancies between systems should reduce by 95%, significantly improving the accuracy of customer information across all touchpoints.</p> <ul> <li> <em>Example</em>: Address updates made by customers will be reflected across all systems within 30 seconds, ensuring accurate billing and service delivery.</li> </ul> </li> <li> <p><strong>Operational Efficiency</strong>: The time required for launching new services or plans should decrease by 60%, allowing TelecomCo to be more responsive to market demands.</p> <ul> <li> <em>Example</em>: A new family plan bundle that previously took 2 months to implement across all systems will be ready for market in just 3 weeks.</li> </ul> </li> <li> <p><strong>Scalability</strong>: The new architecture should successfully handle a 40% increase in data volume over 18 months without any performance degradation.</p> <ul> <li> <em>Example</em>: During a major sporting event, the system will process a record 2 million simultaneous data sessions without any noticeable impact on performance.</li> </ul> </li> <li> <p><strong>Cost Savings</strong>: By optimizing data flows and reducing manual interventions, TelecomCo should achieve a 25% reduction in operational costs related to data management and system integration.</p> <ul> <li> <em>Example</em>: The number of staff required for manual data reconciliation between systems will be reduced from a team of 50 to just 10, with those employees reassigned to higher-value tasks.</li> </ul> </li> <li> <p><strong>Improved Regulatory Compliance</strong>: The new architecture will enable TelecomCo to achieve and maintain compliance with GDPR and industry-specific regulations.</p> <ul> <li> <em>Example</em>: Data access requests from customers will be fulfilled within 24 hours, down from 7 days, thanks to the centralized data management and robust auditing capabilities.</li> </ul> </li> <li> <p><strong>Future-Ready Infrastructure</strong>: The scalable, event-driven architecture will position TelecomCo to rapidly adopt and monetize emerging technologies.</p> <ul> <li> <em>Example</em>: TelecomCo will be able to launch a 5G network slicing service for enterprise customers six months ahead of competitors, leveraging the new architecture’s capabilities.</li> </ul> </li> </ul> <p>Key metrics expected to showcase the success of the project:</p> <ul> <li> <strong>Customer Satisfaction</strong>: Net Promoter Score (NPS) should improve by 20 points within six months of full implementation, from 22 to 42.</li> <li> <strong>Revenue Impact</strong>: Accurate real-time billing and faster service activation should contribute to a 15% increase in ARPU (Average Revenue Per User), from $58 to $66.70.</li> <li> <strong>Operational Efficiency</strong>: Mean Time to Resolve (MTTR) for network issues should decrease by 60%, from an average of 6 hours to 2.4 hours, significantly improving service reliability.</li> <li> <strong>Compliance</strong>: Time to respond to regulatory audits should reduce by 70%, from an average of 10 days to 3 days.</li> </ul> <p>This project will not only resolve TelecomCo’s immediate challenges but also position the company for future growth and innovation in the rapidly evolving telecom landscape. The new architecture will provide a foundation for introducing advanced services like 5G network slicing and IoT connectivity solutions, ensuring TelecomCo remains competitive in the market while maintaining the highest standards of data security and regulatory compliance.</p> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Shubham Nagar. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-projects",title:"projects",description:"A growing collection of my data projects.",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-cv",title:"cv",description:"",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"post-migrating-from-tableau-to-power-bi-a-comprehensive-guide",title:'Migrating from Tableau to Power BI: A Comprehensive Guide <svg width="1.2rem" height="1.2rem" top=".5rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"",section:"Posts",handler:()=>{window.open("https://medium.com/mind-and-machine/migrating-from-tableau-to-power-bi-a-comprehensive-guide-b6e4929e1ea3?source=rss-5ad90eb46828------2","_blank")}},{id:"post-discovering-anomalies-with-mad-the-secret-sauce-for-accurate-data-analysis",title:'Discovering Anomalies with MAD: The Secret Sauce for Accurate Data Analysis <svg width="1.2rem" height="1.2rem" top=".5rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"",section:"Posts",handler:()=>{window.open("https://medium.com/mind-and-machine/discovering-anomalies-with-mad-the-secret-sauce-for-accurate-data-analysis-ed1c7909e2bf?source=rss-5ad90eb46828------2","_blank")}},{id:"post-harnessing-agentic-rag-and-graph-based-metadata-filtering-for-enhanced-information-retrieval",title:'Harnessing Agentic RAG and Graph-Based Metadata Filtering for Enhanced Information Retrieval <svg width="1.2rem" height="1.2rem" top=".5rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"",section:"Posts",handler:()=>{window.open("https://medium.com/mind-and-machine/harnessing-agentic-rag-and-graph-based-metadata-filtering-for-enhanced-information-retrieval-5e4fc88dcdc0?source=rss-5ad90eb46828------2","_blank")}},{id:"post-the-critical-role-of-red-teaming-in-ai-development",title:'The Critical Role of Red Teaming in AI Development <svg width="1.2rem" height="1.2rem" top=".5rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"",section:"Posts",handler:()=>{window.open("https://medium.com/mind-and-machine/the-critical-role-of-red-teaming-in-ai-development-8a1b393cfc51?source=rss-5ad90eb46828------2","_blank")}},{id:"post-who-am-i",title:'Who am I? <svg width="1.2rem" height="1.2rem" top=".5rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"",section:"Posts",handler:()=>{window.open("https://medium.com/@mail.shubhamnagar/who-am-i-f6810254e1ba?source=rss-5ad90eb46828------2","_blank")}},{id:"post-trust-or-distrust-bridging-ai-and-blockchain",title:'Trust or Distrust: Bridging AI and Blockchain <svg width="1.2rem" height="1.2rem" top=".5rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"",section:"Posts",handler:()=>{window.open("https://medium.com/mind-and-machine/trust-or-distrust-bridging-ai-and-blockchain-659c5760ef6?source=rss-5ad90eb46828------2","_blank")}},{id:"post-ai-technologies-in-the-new-era-catalysts-or-hindrances-for-the-rpa-industry",title:'AI Technologies in the New Era: Catalysts or Hindrances for the RPA Industry?... <svg width="1.2rem" height="1.2rem" top=".5rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"",section:"Posts",handler:()=>{window.open("https://medium.com/@mail.shubhamnagar/ai-technologies-in-the-new-era-catalysts-or-hindrances-for-the-rpa-industry-e3c083950ced?source=rss-5ad90eb46828------2","_blank")}},{id:"news-a-simple-inline-announcement",title:"A simple inline announcement.",description:"",section:"News"},{id:"news-a-long-announcement-with-details",title:"A long announcement with details",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_2/"}},{id:"news-a-simple-inline-announcement-with-markdown-emoji-sparkles-smile",title:'A simple inline announcement with Markdown emoji! <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20">',description:"",section:"News"},{id:"projects-advanced-supply-chain-analytics-platform-optimizing-global-logistics-with-real-time-data",title:"Advanced Supply Chain Analytics Platform - Optimizing Global Logistics with Real-time Data",description:"Developed a cutting-edge supply chain analytics platform integrating real-time IoT data, predictive analytics, and interactive visualizations to optimize global logistics operations.",section:"Projects",handler:()=>{window.location.href="/projects/(Analytics)-advanced-data-visualization-project/"}},{id:"projects-data-modeling-for-e-commerce-reducing-redundancy-and-improving-customer-insights",title:"Data Modeling for E-commerce - Reducing Redundancy and Improving Customer Insights",description:"A comprehensive overhaul of an e-commerce platform's data model, resulting in 40% reduced data redundancy and 25% improved customer segmentation accuracy.",section:"Projects",handler:()=>{window.location.href="/projects/(Analytics)-ecommerce-data-modeling/"}},{id:"projects-snowflake-data-warehousing-project-optimizing-analytics-for-scale",title:"Snowflake Data Warehousing Project - Optimizing Analytics for Scale",description:"Implemented a Snowflake data warehouse solution, achieving a 40% reduction in query times and enabling real-time analytics across diverse data sources for a rapidly growing e-commerce company.",section:"Projects",handler:()=>{window.location.href="/projects/(Analytics)-snowflake-project/"}},{id:"projects-data-architecture-strategy-data-silos-ai-implementaion",title:"Data Architecture Strategy - Data Silos - AI Implementaion",description:"Enterprise Data Architect Case Study - Enabling AI Integration in Global Logistics",section:"Projects",handler:()=>{window.location.href="/projects/(DA)-AI-Implementaion/"}},{id:"projects-comprehensive-data-architecture-strategy-for-global-supply-chain-and-logistics",title:"Comprehensive Data Architecture Strategy for Global Supply Chain and Logistics",description:"Designed and implemented a comprehensive data architecture strategy for a global supply chain and logistics customer, improving data accessibility by 35% and streamlining reporting processes across their international operations.",section:"Projects",handler:()=>{window.location.href="/projects/(DA)-comprehensive-data-architecture-strategy/"}},{id:"projects-data-lake-to-data-fabric-modernizing-data-architecture-for-a-multinational-corporation",title:"Data Lake to Data Fabric - Modernizing Data Architecture for a Multinational Corporation...",description:"Transitioning from a traditional data lake to a data fabric approach, improving data accessibility, governance, and analytics agility",section:"Projects",handler:()=>{window.location.href="/projects/(DA)-data-fabric-case-study/"}},{id:"projects-data-pipeline-management-with-apache-spark-and-talend",title:"Data Pipeline Management with Apache Spark and Talend",description:"Designed and managed data pipelines for data validation, transformation, and cleaning using Apache Spark and Talend, ensuring the highest quality and reliability of data across the organization.",section:"Projects",handler:()=>{window.location.href="/projects/(DA)-data-pipeline-management/"}},{id:"projects-so-what-data-should-you-manage-as-master-data",title:"So, What Data Should You Manage as Master Data?",description:"Understanding Master Data Management for telco",section:"Projects",handler:()=>{window.location.href="/projects/(DG)-MDM-Telco/"}},{id:"projects-initiating-supply-chain-transparency-with-mdm",title:"Initiating Supply Chain Transparency with MDM",description:"EcoTrace Solutions - Initiating Supply Chain Transparency with MDM",section:"Projects",handler:()=>{window.location.href="/projects/(DG)-MDM-experience/"}},{id:"projects-revolutionizing-telecom-analytics-oss-bss-data-governance-and-warehousing",title:"Revolutionizing Telecom Analytics - OSS/BSS Data Governance and Warehousing",description:"A comprehensive data governance and analytics solution for a leading telecom company",section:"Projects",handler:()=>{window.location.href="/projects/(DG)-OSS-BSS/"}},{id:"projects-enhancing-metadata-management-using-collibra-business-glossary",title:"Enhancing Metadata Management Using Collibra Business Glossary",description:"Implemented a robust metadata management system using Collibra and integrated it with Mega HOPEX for improved data governance and consistency across the organization.",section:"Projects",handler:()=>{window.location.href="/projects/(DG)-collibra-metadata-case-study/"}},{id:"projects-revolutionizing-supply-chain-data-governance-at-globallogistics",title:"Revolutionizing Supply Chain Data Governance at GlobalLogistics",description:"Implementing enterprise-wide data standards and quality measures to streamline global logistics operations",section:"Projects",handler:()=>{window.location.href="/projects/(DG)-data-governance-collibra/"}},{id:"projects-pioneering-data-governance-in-fashion-supply-chain-transparency",title:"Pioneering Data Governance in Fashion Supply Chain Transparency",description:"Pioneering Data Governance in Fashion Supply Chain Transparency",section:"Projects",handler:()=>{window.location.href="/projects/(DG)-data-governance-exp/"}},{id:"projects-implementing-data-governance-a-journey-from-silos-to-standardization",title:"Implementing Data Governance - A Journey from Silos to Standardization",description:"Transforming organizational data management through strategic governance initiatives",section:"Projects",handler:()=>{window.location.href="/projects/(DG)-implementing-data-governance/"}},{id:"projects-mdm-amp-dg-journey",title:"MDM & DG Journey",description:"Understanding Master Data Management for telco",section:"Projects",handler:()=>{window.location.href="/projects/(DG)-mdm-experinced-final/"}},{id:"projects-enhancing-regulatory-compliance-and-data-governance-in-global-supply-chain-operations",title:"Enhancing Regulatory Compliance and Data Governance in Global Supply Chain Operations",description:"A case study on implementing Collibra and Mega HOPEX to streamline compliance and data management for GlobalLogistics",section:"Projects",handler:()=>{window.location.href="/projects/(DG)-regulatory-compliance/"}},{id:"projects-data-integration-project-telco-colibra",title:"Data Integration Project (Telco) - Colibra",description:"Implemented a comprehensive data integration solution for a global logistics company using Collibra and Mega HOPEX, resulting in improved operational efficiency and data-driven decision making.",section:"Projects",handler:()=>{window.location.href="/projects/(DI)-colibra-data-integration-telco/"}},{id:"projects-data-integration-project-supply-chain-colibra",title:"Data Integration Project (Supply Chain) - Colibra",description:"Implemented a comprehensive data integration solution for a global logistics company using Collibra and Mega HOPEX, resulting in improved operational efficiency and data-driven decision making.",section:"Projects",handler:()=>{window.location.href="/projects/(DI)-colibra-data-integration/"}},{id:"projects-esg-compliance-regional-telecom",title:"ESG Compliance - Regional Telecom",description:"A comprehensive data architecture overhaul to meet emerging ESG standards and optimize telecom operations in Belgium",section:"Projects",handler:()=>{window.location.href="/projects/(DI)-esg-telco/"}},{id:"projects-esg-compliance-supply-chain",title:"ESG Compliance - Supply Chain",description:"A comprehensive data architecture overhaul to meet emerging ESG standards and optimize supply chain operations",section:"Projects",handler:()=>{window.location.href="/projects/(DI)-esg/"}},{id:"projects-modernizing-supply-chain-integration-at-globallogistics",title:"Modernizing Supply Chain Integration at GlobalLogistics",description:"Implementing cutting-edge integration technologies to streamline global supply chain operations",section:"Projects",handler:()=>{window.location.href="/projects/(DI)-modern-supply-chain/"}},{id:"projects-modernizing-telco-integration-at-belgicom",title:"Modernizing Telco Integration at BelgiCom",description:"Implementation of cutting-edge integration technologies to streamline telecom operations",section:"Projects",handler:()=>{window.location.href="/projects/(DI)-modern-telco-integration/"}},{id:"projects-streamlining-supply-chain-data-architecture-at-globallogistics",title:"Streamlining Supply Chain Data Architecture at GlobalLogistics",description:"A comprehensive data integration project that revolutionized GlobalLogistics' supply chain operations",section:"Projects",handler:()=>{window.location.href="/projects/(DI)-streamlining-supply-chain-architecture/"}},{id:"projects-proposed-solution-revolutionizing-telecom-operations-with-sqs-kafka-and-mulesoft",title:"Proposed Solution - Revolutionizing Telecom Operations with SQS, Kafka, and MuleSoft",description:"A forward-looking plan to transform data flows and system integration for enhanced customer experience, operational efficiency, and regulatory compliance",section:"Projects",handler:()=>{window.location.href="/projects/(Messaging)-Telco-use-case/"}},{id:"projects-scalable-real-time-data-platform-for-e-commerce",title:"Scalable Real-Time Data Platform for E-Commerce",description:"Implemented a high-performance data platform using API-first design, Kafka, FastAPI, and Airflow for an e-commerce giant, enabling real-time personalization and handling over 100,000 requests per second.",section:"Projects",handler:()=>{window.location.href="/projects/(Messaging)-realtime-data-platform/"}},{id:"projects-databricks",title:"Databricks",description:"Databricks Supply Chain Integration - A Case Study",section:"Projects",handler:()=>{window.location.href="/projects/(Tools)-Databricks/"}},{id:"projects-netcracker-oss",title:"NetCracker OSS",description:"NetCracker for Network Management",section:"Projects",handler:()=>{window.location.href="/projects/(Tools)-Netcracker/"}},{id:"projects-snowflake",title:"Snowflake",description:"Snowflake Supply Chain Integration - A Case Study",section:"Projects",handler:()=>{window.location.href="/projects/(Tools)-Snowflake/"}},{id:"projects-talend-data-integration",title:"Talend Data Integration",description:"Talend How and Why",section:"Projects",handler:()=>{window.location.href="/projects/(Tools)-Talend/"}},{id:"projects-apache-kafka",title:"Apache kafka",description:"Kafka How and Why",section:"Projects",handler:()=>{window.location.href="/projects/(Tools)-apache-kafka/"}},{id:"projects-apache-spark",title:"Apache spark",description:"Spark How and Why",section:"Projects",handler:()=>{window.location.href="/projects/(Tools)-apche-spark/"}},{id:"projects-aws-sqs",title:"AWS SQS",description:"SQS How and Why",section:"Projects",handler:()=>{window.location.href="/projects/(Tools)-aws-sqs/"}},{id:"projects-how-collibra-and-leanix-complement-each-other-in-telecom",title:"How Collibra and LeanIX Complement Each Other in Telecom",description:"How Collibra and LeanIX Complement Each Other in Telecom",section:"Projects",handler:()=>{window.location.href="/projects/(Tools)-collibra-plus-leanix/"}},{id:"projects-collibra",title:"Collibra",description:"Collibra Explained Simply",section:"Projects",handler:()=>{window.location.href="/projects/(Tools)-collibra/"}},{id:"projects-sap-leanix",title:"SAP LeanIX",description:"LeanIX Explained Simply",section:"Projects",handler:()=>{window.location.href="/projects/(Tools)-leanix/"}},{id:"projects-mulesoft",title:"Mulesoft",description:"A deep dive into how MuleSoft Anypoint Platform transformed global supply chain operations",section:"Projects",handler:()=>{window.location.href="/projects/(Tools)-mulesoft/"}},{id:"projects-sqs-vs-kafka",title:"SQS vs Kafka",description:"Complementing Kafka with SQS",section:"Projects",handler:()=>{window.location.href="/projects/(Tools)-sqs-kafka/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%6D%61%69%6C.%73%68%75%62%68%61%6D%6E%61%67%61%72@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/shubham184","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/shubham-nagar-222497151","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>